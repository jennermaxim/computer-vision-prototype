"""
Integrated AI-Powered Learning Platform
Combines vision detection, mission generation, and problem classification
"""
from typing import Dict, Optional, List
from vision_detector import CommunityIssueDetector
from mission_generator import MissionStatementGenerator
from problem_classifier import ProblemClassifier
from config import Config


class AILearningPlatform:
    """
    Complete AI-powered learning platform that:
    1. Detects community issues from images
    2. Converts descriptions into mission statements
    3. Classifies problems into categories
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize the integrated platform
        
        Args:
            api_key: OpenAI API key (uses Config if not provided)
        """
        Config.validate()
        
        self.vision_detector = CommunityIssueDetector(api_key)
        self.mission_generator = MissionStatementGenerator(api_key)
        self.problem_classifier = ProblemClassifier(api_key)
    
    def process_image(self, image_path: str, 
                     domains: Optional[List[str]] = None) -> Dict:
        """
        Complete workflow: Detect issues in image, classify, and generate mission
        
        Args:
            image_path: Path to image or URL
            domains: Specific domains to analyze
            
        Returns:
            Complete analysis results
        """
        print("ðŸ” Analyzing image for community issues...")
        
        # Step 1: Detect issues in the image
        vision_result = self.vision_detector.detect_issues(image_path, domains)
        
        if not vision_result['success']:
            return {
                'success': False,
                'error': vision_result.get('error', 'Vision detection failed'),
                'step': 'vision_detection'
            }
        
        print("âœ… Issues detected in image")
        print("\nðŸ“‹ Classifying the detected problems...")
        
        # Step 2: Classify the detected issues
        classification = self.problem_classifier.classify_with_vision_analysis(
            vision_result['analysis']
        )
        
        print(f"âœ… Classified as: {classification.get('category', 'Unknown')}")
        
        # Step 3: Extract key problem description for mission generation
        problem_desc = self._extract_problem_description(vision_result['analysis'])
        
        print("\nðŸŽ¯ Generating mission statement...")
        
        # Step 4: Generate mission statement
        mission = self.mission_generator.generate_mission_statement(
            problem_desc,
            context=f"Based on visual analysis. Category: {classification.get('category')}"
        )
        
        print("âœ… Mission statement generated")
        
        return {
            'success': True,
            'image_path': image_path,
            'vision_analysis': vision_result['analysis'],
            'classification': classification,
            'mission_statement': mission,
            'summary': self._create_summary(vision_result, classification, mission)
        }
    
    def process_text_description(self, problem_description: str) -> Dict:
        """
        Process a text description: Classify and generate mission
        
        Args:
            problem_description: User's description of the problem
            
        Returns:
            Analysis results
        """
        print("ðŸ“ Processing problem description...")
        
        # Step 1: Classify the problem
        classification = self.problem_classifier.classify_problem(problem_description)
        
        if not classification['success']:
            return {
                'success': False,
                'error': classification.get('error', 'Classification failed'),
                'step': 'classification'
            }
        
        print(f"âœ… Classified as: {classification['category']}")
        print("\nðŸŽ¯ Generating mission statement...")
        
        # Step 2: Generate mission statement
        mission = self.mission_generator.generate_mission_statement(
            problem_description,
            context=f"Category: {classification['category']}"
        )
        
        if not mission['success']:
            return {
                'success': False,
                'error': mission.get('error', 'Mission generation failed'),
                'step': 'mission_generation',
                'classification': classification
            }
        
        print("âœ… Mission statement generated")
        
        return {
            'success': True,
            'original_description': problem_description,
            'classification': classification,
            'mission_statement': mission,
            'summary': self._create_text_summary(problem_description, classification, mission)
        }
    
    def process_multiple_images(self, image_paths: List[str]) -> List[Dict]:
        """
        Process multiple images
        
        Args:
            image_paths: List of image paths or URLs
            
        Returns:
            List of analysis results
        """
        results = []
        for i, image_path in enumerate(image_paths, 1):
            print(f"\n{'='*60}")
            print(f"Processing Image {i}/{len(image_paths)}")
            print(f"{'='*60}")
            
            result = self.process_image(image_path)
            results.append(result)
        
        return results
    
    def _extract_problem_description(self, vision_analysis: str) -> str:
        """
        Extract a concise problem description from vision analysis
        
        Args:
            vision_analysis: Full vision analysis text
            
        Returns:
            Extracted problem description
        """
        # Look for detected issues section
        if "DETECTED ISSUES:" in vision_analysis:
            start = vision_analysis.find("DETECTED ISSUES:")
            end = vision_analysis.find("VISUAL EVIDENCE:", start)
            if end == -1:
                end = vision_analysis.find("RECOMMENDATIONS:", start)
            if end == -1:
                end = len(vision_analysis)
            
            issues_section = vision_analysis[start:end].strip()
            # Take first few lines as description
            lines = [line.strip() for line in issues_section.split('\n') 
                    if line.strip() and not line.strip().startswith('DETECTED')]
            return ' '.join(lines[:3]) if lines else vision_analysis[:200]
        
        # Fallback: use first 200 characters
        return vision_analysis[:200].strip()
    
    def _create_summary(self, vision_result: Dict, classification: Dict, 
                       mission: Dict) -> str:
        """
        Create a formatted summary of the complete analysis
        
        Args:
            vision_result: Vision detection results
            classification: Classification results
            mission: Mission statement results
            
        Returns:
            Formatted summary string
        """
        summary = f"""
{'='*70}
                    COMMUNITY ISSUE ANALYSIS SUMMARY
{'='*70}

ðŸ” VISION ANALYSIS:
{'-'*70}
{vision_result['analysis'][:500]}...

ðŸ“Š CLASSIFICATION:
{'-'*70}
Category: {classification.get('category', 'Unknown')}
Confidence: {classification.get('confidence', 'Unknown')}

ðŸŽ¯ MISSION STATEMENT:
{'-'*70}
{mission.get('mission_statement', 'N/A')}

ðŸ“ PROBLEM DEFINITION:
{mission.get('problem_definition', 'N/A')}

ðŸŽ EXPECTED IMPACT:
{mission.get('expected_impact', 'N/A')}

{'='*70}
"""
        return summary
    
    def _create_text_summary(self, description: str, classification: Dict, 
                           mission: Dict) -> str:
        """
        Create a formatted summary for text-based analysis
        
        Args:
            description: Original problem description
            classification: Classification results
            mission: Mission statement results
            
        Returns:
            Formatted summary string
        """
        summary = f"""
{'='*70}
                    PROBLEM ANALYSIS SUMMARY
{'='*70}

ðŸ“ ORIGINAL DESCRIPTION:
{'-'*70}
{description}

ðŸ“Š CLASSIFICATION:
{'-'*70}
Category: {classification.get('category', 'Unknown')}
Confidence: {classification.get('confidence', 'Unknown')}
Reasoning: {classification.get('reasoning', 'N/A')[:200]}

ðŸŽ¯ MISSION STATEMENT:
{'-'*70}
{mission.get('mission_statement', 'N/A')}

ðŸŽ EXPECTED IMPACT:
{mission.get('expected_impact', 'N/A')}

ðŸ“‹ ACTION STEPS:
{'-'*70}
"""
        for i, step in enumerate(mission.get('action_steps', []), 1):
            summary += f"{i}. {step}\n"
        
        summary += f"\n{'='*70}\n"
        return summary


# Convenience function for quick testing
def analyze_community_issue(source: str, source_type: str = 'auto') -> Dict:
    """
    Analyze a community issue from image or text
    
    Args:
        source: Image path/URL or text description
        source_type: 'image', 'text', or 'auto' (auto-detect)
        
    Returns:
        Complete analysis results
    """
    platform = AILearningPlatform()
    
    # Auto-detect source type
    if source_type == 'auto':
        if (source.startswith('http://') or source.startswith('https://') or 
            source.endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp'))):
            source_type = 'image'
        else:
            source_type = 'text'
    
    if source_type == 'image':
        return platform.process_image(source)
    else:
        return platform.process_text_description(source)
